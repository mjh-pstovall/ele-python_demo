{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa63208f",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is the goto library for importing, changing, validating, and exporting datasets. It is able to import most file types and convert them to a 'DataFrame', like a DataTable in C#. Once the dataframe is created, pandas offers lots of ways to change and query the data, and supports exporting in multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec('pandas') is None:\n",
    "    %pip install pandas\n",
    "\n",
    "if importlib.util.find_spec('pandas[excel]') is None:\n",
    "    %pip install \"pandas[excel]\"\n",
    "    \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae688d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame with some sample data\n",
    "# Note the use of different data types in the columns\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'C': [True, False, True, False, True],\n",
    "    'D': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'E': pd.date_range('20230101', periods=5)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.index.name = 'Index'  # Set the index name for clarity\n",
    "df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas allows for easy querying and manipulation of data\n",
    "\n",
    "# For example, we can filter rows where column 'A' is greater than 2\n",
    "filtered_df = df[df['A'] > 2]\n",
    "\n",
    "# Or where column 'C' is True\n",
    "true_filtered_df = df[df['C']]\n",
    "\n",
    "# We can also perform operations like adding a new column\n",
    "df['F'] = df['A'] * df['D']  # New column 'F' as product of 'A' and 'D'\n",
    "\n",
    "# Or apply functions to columns\n",
    "df['G'] = df['B'].str.upper()  # New column 'G' with uppercase values of 'B'\n",
    "\n",
    "# Lastly, we can select specific columns to display\n",
    "df[['F', 'B', 'G']].head()\n",
    "\n",
    "# There are many more operations available in pandas, such as groupby, merge, and pivot_table,\n",
    "# which allow for complex data analysis and manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Export\n",
    "\n",
    "# Create a directory for saving the exported files if it doesn't exist\n",
    "import os\n",
    "os.makedirs('example_data', exist_ok=True)\n",
    "\n",
    "# DataFrames can be easily exported to various formats.\n",
    "# For example, to CSV:\n",
    "df.to_csv('example_data/test_dataframe.csv', index=True)\n",
    "\n",
    "# To Excel:\n",
    "df.to_excel('example_data/test_dataframe.xlsx', index=True)\n",
    "\n",
    "# To JSON:\n",
    "df.to_json('example_data/test_dataframe.json', indent=4, orient='records')\n",
    "\n",
    "# We can save the DataFrame to a pickle file for quick loading later\n",
    "# This file format is useful for preserving the DataFrame metadata, like the exact structure and data types.\n",
    "# It also makes for faster loading compared to CSV or Excel formats.\n",
    "# Its also called a pickle file, which is hilarious.\n",
    "df.to_pickle('example_data/test_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, pandas makes for easy loading of data back into a DataFrame from these formats.\n",
    "import shutil\n",
    "\n",
    "# Loading from CSV\n",
    "loaded_csv_df = pd.read_csv('example_data/test_dataframe.csv', index_col='Index')\n",
    "print('CSV\\n', loaded_csv_df.head(1))  # Display the first few rows of the loaded CSV DataFrame\n",
    "\n",
    "# Loading from Excel\n",
    "loaded_excel_df = pd.read_excel('example_data/test_dataframe.xlsx', index_col='Index')\n",
    "print('\\n\\nEXCEL\\n', loaded_excel_df.head(1))  # Display the first few rows of the loaded Excel DataFrame\n",
    "\n",
    "# Loading from JSON\n",
    "loaded_json_df = pd.read_json('example_data/test_dataframe.json')\n",
    "print('\\n\\nJSON\\n', loaded_json_df.head(1))  # Display the first few rows of the loaded JSON DataFrame\n",
    "\n",
    "# Loading from pickle\n",
    "loaded_pickle_df = pd.read_pickle('example_data/test_dataframe.pkl')\n",
    "print('\\n\\nPICKLE\\n', loaded_pickle_df.head(1))  # Display the first few rows of the loaded pickle DataFrame\n",
    "\n",
    "# Delete the example_data directory and its contents\n",
    "shutil.rmtree('example_data', ignore_errors=True) # This will remove the directory and all files within it, cleaning up after our example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
